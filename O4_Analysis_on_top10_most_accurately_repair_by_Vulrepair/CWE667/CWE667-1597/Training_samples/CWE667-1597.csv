cwe_id,source,target,project_and_commit_id,cve_id,original_address,time
CWE-362,"CWE-362 void uverbs_user_mmap_disassociate ( struct ib_uverbs_file * ufile ) { struct rdma_umap_priv * priv , * next_priv ; lockdep_assert_held ( & ufile -> hw_destroy_rwsem ) ; while ( 1 ) { struct mm_struct * mm = NULL ; mutex_lock ( & ufile -> umap_lock ) ; while ( ! list_empty ( & ufile -> umaps ) ) { int ret ; priv = list_first_entry ( & ufile -> umaps , struct rdma_umap_priv , list ) ; mm = priv -> vma -> vm_mm ; ret = mmget_not_zero ( mm ) ; if ( ! ret ) { list_del_init ( & priv -> list ) ; mm = NULL ; continue ; } break ; } mutex_unlock ( & ufile -> umap_lock ) ; if ( ! mm ) return ; <S2SV_StartBug> down_write ( & mm -> mmap_sem ) ; <S2SV_EndBug> mutex_lock ( & ufile -> umap_lock ) ; list_for_each_entry_safe ( priv , next_priv , & ufile -> umaps , list ) { struct vm_area_struct * vma = priv -> vma ; if ( vma -> vm_mm != mm ) continue ; list_del_init ( & priv -> list ) ; zap_vma_ptes ( vma , vma -> vm_start , vma -> vm_end - vma -> vm_start ) ; vma -> vm_flags &= ~ ( VM_SHARED | VM_MAYSHARE ) ; } mutex_unlock ( & ufile -> umap_lock ) ; <S2SV_StartBug> up_write ( & mm -> mmap_sem ) ; <S2SV_EndBug> mmput ( mm ) ; } }
","<S2SV_ModStart> -> mmap_sem ) ; if ( ! mmget_still_valid ( mm ) ) goto skip_mm <S2SV_ModStart> umap_lock ) ; skip_mm :
",torvalds@linux/04f5866e41fb70690e28397487d8bd8eea7d712a,CVE-2019-11599,https://github.com/torvalds/linux/commit/04f5866e41fb70690e28397487d8bd8eea7d712a,2019-04-29T18:29Z
CWE-362,"CWE-362 static int userfaultfd_unregister ( struct userfaultfd_ctx * ctx , unsigned long arg ) { struct mm_struct * mm = ctx -> mm ; struct vm_area_struct * vma , * prev , * cur ; int ret ; struct uffdio_range uffdio_unregister ; unsigned long new_flags ; bool found ; unsigned long start , end , vma_end ; const void __user * buf = ( void __user * ) arg ; ret = - EFAULT ; if ( copy_from_user ( & uffdio_unregister , buf , sizeof ( uffdio_unregister ) ) ) goto out ; ret = validate_range ( mm , uffdio_unregister . start , uffdio_unregister . len ) ; if ( ret ) goto out ; start = uffdio_unregister . start ; end = start + uffdio_unregister . len ; ret = - ENOMEM ; if ( ! mmget_not_zero ( mm ) ) goto out ; down_write ( & mm -> mmap_sem ) ; <S2SV_StartBug> vma = find_vma_prev ( mm , start , & prev ) ; <S2SV_EndBug> if ( ! vma ) goto out_unlock ; ret = - EINVAL ; if ( vma -> vm_start >= end ) goto out_unlock ; if ( is_vm_hugetlb_page ( vma ) ) { unsigned long vma_hpagesize = vma_kernel_pagesize ( vma ) ; if ( start & ( vma_hpagesize - 1 ) ) goto out_unlock ; } found = false ; ret = - EINVAL ; for ( cur = vma ; cur && cur -> vm_start < end ; cur = cur -> vm_next ) { cond_resched ( ) ; BUG_ON ( ! ! cur -> vm_userfaultfd_ctx . ctx ^ ! ! ( cur -> vm_flags & ( VM_UFFD_MISSING | VM_UFFD_WP ) ) ) ; if ( ! vma_can_userfault ( cur ) ) goto out_unlock ; found = true ; } BUG_ON ( ! found ) ; if ( vma -> vm_start < start ) prev = vma ; ret = 0 ; do { cond_resched ( ) ; BUG_ON ( ! vma_can_userfault ( vma ) ) ; if ( ! vma -> vm_userfaultfd_ctx . ctx ) goto skip ; WARN_ON ( ! ( vma -> vm_flags & VM_MAYWRITE ) ) ; if ( vma -> vm_start > start ) start = vma -> vm_start ; vma_end = min ( end , vma -> vm_end ) ; if ( userfaultfd_missing ( vma ) ) { struct userfaultfd_wake_range range ; range . start = start ; range . len = vma_end - start ; wake_userfault ( vma -> vm_userfaultfd_ctx . ctx , & range ) ; } new_flags = vma -> vm_flags & ~ ( VM_UFFD_MISSING | VM_UFFD_WP ) ; prev = vma_merge ( mm , prev , start , vma_end , new_flags , vma -> anon_vma , vma -> vm_file , vma -> vm_pgoff , vma_policy ( vma ) , NULL_VM_UFFD_CTX ) ; if ( prev ) { vma = prev ; goto next ; } if ( vma -> vm_start < start ) { ret = split_vma ( mm , vma , start , 1 ) ; if ( ret ) break ; } if ( vma -> vm_end > end ) { ret = split_vma ( mm , vma , end , 0 ) ; if ( ret ) break ; } next : vma -> vm_flags = new_flags ; vma -> vm_userfaultfd_ctx = NULL_VM_UFFD_CTX ; skip : prev = vma ; start = vma -> vm_end ; vma = vma -> vm_next ; } while ( vma && vma -> vm_start < end ) ; out_unlock : up_write ( & mm -> mmap_sem ) ; mmput ( mm ) ; out : return ret ; }
","<S2SV_ModStart> mmap_sem ) ; if ( ! mmget_still_valid ( mm ) ) goto out_unlock ;
",torvalds@linux/04f5866e41fb70690e28397487d8bd8eea7d712a,CVE-2019-11599,https://github.com/torvalds/linux/commit/04f5866e41fb70690e28397487d8bd8eea7d712a,2019-04-29T18:29Z
CWE-362,"CWE-362 static int userfaultfd_release ( struct inode * inode , struct file * file ) { struct userfaultfd_ctx * ctx = file -> private_data ; struct mm_struct * mm = ctx -> mm ; struct vm_area_struct * vma , * prev ; struct userfaultfd_wake_range range = { . len = 0 , } ; unsigned long new_flags ; WRITE_ONCE ( ctx -> released , true ) ; if ( ! mmget_not_zero ( mm ) ) goto wakeup ; down_write ( & mm -> mmap_sem ) ; <S2SV_StartBug> prev = NULL ; <S2SV_EndBug> for ( vma = mm -> mmap ; vma ; vma = vma -> vm_next ) { cond_resched ( ) ; BUG_ON ( ! ! vma -> vm_userfaultfd_ctx . ctx ^ ! ! ( vma -> vm_flags & ( VM_UFFD_MISSING | VM_UFFD_WP ) ) ) ; if ( vma -> vm_userfaultfd_ctx . ctx != ctx ) { prev = vma ; continue ; } new_flags = vma -> vm_flags & ~ ( VM_UFFD_MISSING | VM_UFFD_WP ) ; prev = vma_merge ( mm , prev , vma -> vm_start , vma -> vm_end , new_flags , vma -> anon_vma , vma -> vm_file , vma -> vm_pgoff , vma_policy ( vma ) , NULL_VM_UFFD_CTX ) ; if ( prev ) vma = prev ; else prev = vma ; vma -> vm_flags = new_flags ; vma -> vm_userfaultfd_ctx = NULL_VM_UFFD_CTX ; } <S2SV_StartBug> up_write ( & mm -> mmap_sem ) ; <S2SV_EndBug> mmput ( mm ) ; wakeup : spin_lock ( & ctx -> fault_pending_wqh . lock ) ; __wake_up_locked_key ( & ctx -> fault_pending_wqh , TASK_NORMAL , & range ) ; __wake_up ( & ctx -> fault_wqh , TASK_NORMAL , 1 , & range ) ; spin_unlock ( & ctx -> fault_pending_wqh . lock ) ; wake_up_all ( & ctx -> event_wqh ) ; wake_up_poll ( & ctx -> fd_wqh , EPOLLHUP ) ; userfaultfd_ctx_put ( ctx ) ; return 0 ; }
","<S2SV_ModStart> mmap_sem ) ; if ( ! mmget_still_valid ( mm ) ) goto skip_mm ; <S2SV_ModStart> NULL_VM_UFFD_CTX ; } skip_mm :
",torvalds@linux/04f5866e41fb70690e28397487d8bd8eea7d712a,CVE-2019-11599,https://github.com/torvalds/linux/commit/04f5866e41fb70690e28397487d8bd8eea7d712a,2019-04-29T18:29Z
CWE-667,"CWE-667 void uverbs_user_mmap_disassociate ( struct ib_uverbs_file * ufile ) { struct rdma_umap_priv * priv , * next_priv ; lockdep_assert_held ( & ufile -> hw_destroy_rwsem ) ; while ( 1 ) { struct mm_struct * mm = NULL ; mutex_lock ( & ufile -> umap_lock ) ; while ( ! list_empty ( & ufile -> umaps ) ) { int ret ; priv = list_first_entry ( & ufile -> umaps , struct rdma_umap_priv , list ) ; mm = priv -> vma -> vm_mm ; ret = mmget_not_zero ( mm ) ; if ( ! ret ) { list_del_init ( & priv -> list ) ; mm = NULL ; continue ; } break ; } mutex_unlock ( & ufile -> umap_lock ) ; if ( ! mm ) return ; <S2SV_StartBug> down_write ( & mm -> mmap_sem ) ; <S2SV_EndBug> mutex_lock ( & ufile -> umap_lock ) ; list_for_each_entry_safe ( priv , next_priv , & ufile -> umaps , list ) { struct vm_area_struct * vma = priv -> vma ; if ( vma -> vm_mm != mm ) continue ; list_del_init ( & priv -> list ) ; zap_vma_ptes ( vma , vma -> vm_start , vma -> vm_end - vma -> vm_start ) ; vma -> vm_flags &= ~ ( VM_SHARED | VM_MAYSHARE ) ; } mutex_unlock ( & ufile -> umap_lock ) ; <S2SV_StartBug> up_write ( & mm -> mmap_sem ) ; <S2SV_EndBug> mmput ( mm ) ; } }
","<S2SV_ModStart> -> mmap_sem ) ; if ( ! mmget_still_valid ( mm ) ) goto skip_mm <S2SV_ModStart> umap_lock ) ; skip_mm :
",torvalds@linux/04f5866e41fb70690e28397487d8bd8eea7d712a,CVE-2019-11599,https://github.com/torvalds/linux/commit/04f5866e41fb70690e28397487d8bd8eea7d712a,2019-04-29T18:29Z
CWE-362,"CWE-362 static void userfaultfd_event_wait_completion ( struct userfaultfd_ctx * ctx , struct userfaultfd_wait_queue * ewq ) { struct userfaultfd_ctx * release_new_ctx ; if ( WARN_ON_ONCE ( current -> flags & PF_EXITING ) ) goto out ; ewq -> ctx = ctx ; init_waitqueue_entry ( & ewq -> wq , current ) ; release_new_ctx = NULL ; spin_lock ( & ctx -> event_wqh . lock ) ; __add_wait_queue ( & ctx -> event_wqh , & ewq -> wq ) ; for ( ; ; ) { set_current_state ( TASK_KILLABLE ) ; if ( ewq -> msg . event == 0 ) break ; if ( READ_ONCE ( ctx -> released ) || fatal_signal_pending ( current ) ) { __remove_wait_queue ( & ctx -> event_wqh , & ewq -> wq ) ; if ( ewq -> msg . event == UFFD_EVENT_FORK ) { struct userfaultfd_ctx * new ; new = ( struct userfaultfd_ctx * ) ( unsigned long ) ewq -> msg . arg . reserved . reserved1 ; release_new_ctx = new ; } break ; } spin_unlock ( & ctx -> event_wqh . lock ) ; wake_up_poll ( & ctx -> fd_wqh , EPOLLIN ) ; schedule ( ) ; spin_lock ( & ctx -> event_wqh . lock ) ; } __set_current_state ( TASK_RUNNING ) ; spin_unlock ( & ctx -> event_wqh . lock ) ; if ( release_new_ctx ) { struct vm_area_struct * vma ; struct mm_struct * mm = release_new_ctx -> mm ; down_write ( & mm -> mmap_sem ) ; <S2SV_StartBug> for ( vma = mm -> mmap ; vma ; vma = vma -> vm_next ) <S2SV_EndBug> if ( vma -> vm_userfaultfd_ctx . ctx == release_new_ctx ) { vma -> vm_userfaultfd_ctx = NULL_VM_UFFD_CTX ; vma -> vm_flags &= ~ ( VM_UFFD_WP | VM_UFFD_MISSING ) ; } up_write ( & mm -> mmap_sem ) ; userfaultfd_ctx_put ( release_new_ctx ) ; } out : WRITE_ONCE ( ctx -> mmap_changing , false ) ; userfaultfd_ctx_put ( ctx ) ; }
","<S2SV_ModStart> mmap_sem ) ; VM_WARN_ON ( ! mmget_still_valid ( mm ) ) ;
",torvalds@linux/04f5866e41fb70690e28397487d8bd8eea7d712a,CVE-2019-11599,https://github.com/torvalds/linux/commit/04f5866e41fb70690e28397487d8bd8eea7d712a,2019-04-29T18:29Z
CWE-667,"CWE-667 static int userfaultfd_release ( struct inode * inode , struct file * file ) { struct userfaultfd_ctx * ctx = file -> private_data ; struct mm_struct * mm = ctx -> mm ; struct vm_area_struct * vma , * prev ; struct userfaultfd_wake_range range = { . len = 0 , } ; unsigned long new_flags ; WRITE_ONCE ( ctx -> released , true ) ; if ( ! mmget_not_zero ( mm ) ) goto wakeup ; down_write ( & mm -> mmap_sem ) ; <S2SV_StartBug> prev = NULL ; <S2SV_EndBug> for ( vma = mm -> mmap ; vma ; vma = vma -> vm_next ) { cond_resched ( ) ; BUG_ON ( ! ! vma -> vm_userfaultfd_ctx . ctx ^ ! ! ( vma -> vm_flags & ( VM_UFFD_MISSING | VM_UFFD_WP ) ) ) ; if ( vma -> vm_userfaultfd_ctx . ctx != ctx ) { prev = vma ; continue ; } new_flags = vma -> vm_flags & ~ ( VM_UFFD_MISSING | VM_UFFD_WP ) ; prev = vma_merge ( mm , prev , vma -> vm_start , vma -> vm_end , new_flags , vma -> anon_vma , vma -> vm_file , vma -> vm_pgoff , vma_policy ( vma ) , NULL_VM_UFFD_CTX ) ; if ( prev ) vma = prev ; else prev = vma ; vma -> vm_flags = new_flags ; vma -> vm_userfaultfd_ctx = NULL_VM_UFFD_CTX ; } <S2SV_StartBug> up_write ( & mm -> mmap_sem ) ; <S2SV_EndBug> mmput ( mm ) ; wakeup : spin_lock ( & ctx -> fault_pending_wqh . lock ) ; __wake_up_locked_key ( & ctx -> fault_pending_wqh , TASK_NORMAL , & range ) ; __wake_up ( & ctx -> fault_wqh , TASK_NORMAL , 1 , & range ) ; spin_unlock ( & ctx -> fault_pending_wqh . lock ) ; wake_up_all ( & ctx -> event_wqh ) ; wake_up_poll ( & ctx -> fd_wqh , EPOLLHUP ) ; userfaultfd_ctx_put ( ctx ) ; return 0 ; }
","<S2SV_ModStart> mmap_sem ) ; if ( ! mmget_still_valid ( mm ) ) goto skip_mm ; <S2SV_ModStart> NULL_VM_UFFD_CTX ; } skip_mm :
",torvalds@linux/04f5866e41fb70690e28397487d8bd8eea7d712a,CVE-2019-11599,https://github.com/torvalds/linux/commit/04f5866e41fb70690e28397487d8bd8eea7d712a,2019-04-29T18:29Z
CWE-667,"CWE-667 static int userfaultfd_unregister ( struct userfaultfd_ctx * ctx , unsigned long arg ) { struct mm_struct * mm = ctx -> mm ; struct vm_area_struct * vma , * prev , * cur ; int ret ; struct uffdio_range uffdio_unregister ; unsigned long new_flags ; bool found ; unsigned long start , end , vma_end ; const void __user * buf = ( void __user * ) arg ; ret = - EFAULT ; if ( copy_from_user ( & uffdio_unregister , buf , sizeof ( uffdio_unregister ) ) ) goto out ; ret = validate_range ( mm , uffdio_unregister . start , uffdio_unregister . len ) ; if ( ret ) goto out ; start = uffdio_unregister . start ; end = start + uffdio_unregister . len ; ret = - ENOMEM ; if ( ! mmget_not_zero ( mm ) ) goto out ; down_write ( & mm -> mmap_sem ) ; <S2SV_StartBug> vma = find_vma_prev ( mm , start , & prev ) ; <S2SV_EndBug> if ( ! vma ) goto out_unlock ; ret = - EINVAL ; if ( vma -> vm_start >= end ) goto out_unlock ; if ( is_vm_hugetlb_page ( vma ) ) { unsigned long vma_hpagesize = vma_kernel_pagesize ( vma ) ; if ( start & ( vma_hpagesize - 1 ) ) goto out_unlock ; } found = false ; ret = - EINVAL ; for ( cur = vma ; cur && cur -> vm_start < end ; cur = cur -> vm_next ) { cond_resched ( ) ; BUG_ON ( ! ! cur -> vm_userfaultfd_ctx . ctx ^ ! ! ( cur -> vm_flags & ( VM_UFFD_MISSING | VM_UFFD_WP ) ) ) ; if ( ! vma_can_userfault ( cur ) ) goto out_unlock ; found = true ; } BUG_ON ( ! found ) ; if ( vma -> vm_start < start ) prev = vma ; ret = 0 ; do { cond_resched ( ) ; BUG_ON ( ! vma_can_userfault ( vma ) ) ; if ( ! vma -> vm_userfaultfd_ctx . ctx ) goto skip ; WARN_ON ( ! ( vma -> vm_flags & VM_MAYWRITE ) ) ; if ( vma -> vm_start > start ) start = vma -> vm_start ; vma_end = min ( end , vma -> vm_end ) ; if ( userfaultfd_missing ( vma ) ) { struct userfaultfd_wake_range range ; range . start = start ; range . len = vma_end - start ; wake_userfault ( vma -> vm_userfaultfd_ctx . ctx , & range ) ; } new_flags = vma -> vm_flags & ~ ( VM_UFFD_MISSING | VM_UFFD_WP ) ; prev = vma_merge ( mm , prev , start , vma_end , new_flags , vma -> anon_vma , vma -> vm_file , vma -> vm_pgoff , vma_policy ( vma ) , NULL_VM_UFFD_CTX ) ; if ( prev ) { vma = prev ; goto next ; } if ( vma -> vm_start < start ) { ret = split_vma ( mm , vma , start , 1 ) ; if ( ret ) break ; } if ( vma -> vm_end > end ) { ret = split_vma ( mm , vma , end , 0 ) ; if ( ret ) break ; } next : vma -> vm_flags = new_flags ; vma -> vm_userfaultfd_ctx = NULL_VM_UFFD_CTX ; skip : prev = vma ; start = vma -> vm_end ; vma = vma -> vm_next ; } while ( vma && vma -> vm_start < end ) ; out_unlock : up_write ( & mm -> mmap_sem ) ; mmput ( mm ) ; out : return ret ; }
","<S2SV_ModStart> mmap_sem ) ; if ( ! mmget_still_valid ( mm ) ) goto out_unlock ;
",torvalds@linux/04f5866e41fb70690e28397487d8bd8eea7d712a,CVE-2019-11599,https://github.com/torvalds/linux/commit/04f5866e41fb70690e28397487d8bd8eea7d712a,2019-04-29T18:29Z
CWE-667,"CWE-667 static void userfaultfd_event_wait_completion ( struct userfaultfd_ctx * ctx , struct userfaultfd_wait_queue * ewq ) { struct userfaultfd_ctx * release_new_ctx ; if ( WARN_ON_ONCE ( current -> flags & PF_EXITING ) ) goto out ; ewq -> ctx = ctx ; init_waitqueue_entry ( & ewq -> wq , current ) ; release_new_ctx = NULL ; spin_lock ( & ctx -> event_wqh . lock ) ; __add_wait_queue ( & ctx -> event_wqh , & ewq -> wq ) ; for ( ; ; ) { set_current_state ( TASK_KILLABLE ) ; if ( ewq -> msg . event == 0 ) break ; if ( READ_ONCE ( ctx -> released ) || fatal_signal_pending ( current ) ) { __remove_wait_queue ( & ctx -> event_wqh , & ewq -> wq ) ; if ( ewq -> msg . event == UFFD_EVENT_FORK ) { struct userfaultfd_ctx * new ; new = ( struct userfaultfd_ctx * ) ( unsigned long ) ewq -> msg . arg . reserved . reserved1 ; release_new_ctx = new ; } break ; } spin_unlock ( & ctx -> event_wqh . lock ) ; wake_up_poll ( & ctx -> fd_wqh , EPOLLIN ) ; schedule ( ) ; spin_lock ( & ctx -> event_wqh . lock ) ; } __set_current_state ( TASK_RUNNING ) ; spin_unlock ( & ctx -> event_wqh . lock ) ; if ( release_new_ctx ) { struct vm_area_struct * vma ; struct mm_struct * mm = release_new_ctx -> mm ; down_write ( & mm -> mmap_sem ) ; <S2SV_StartBug> for ( vma = mm -> mmap ; vma ; vma = vma -> vm_next ) <S2SV_EndBug> if ( vma -> vm_userfaultfd_ctx . ctx == release_new_ctx ) { vma -> vm_userfaultfd_ctx = NULL_VM_UFFD_CTX ; vma -> vm_flags &= ~ ( VM_UFFD_WP | VM_UFFD_MISSING ) ; } up_write ( & mm -> mmap_sem ) ; userfaultfd_ctx_put ( release_new_ctx ) ; } out : WRITE_ONCE ( ctx -> mmap_changing , false ) ; userfaultfd_ctx_put ( ctx ) ; }
","<S2SV_ModStart> mmap_sem ) ; VM_WARN_ON ( ! mmget_still_valid ( mm ) ) ;
",torvalds@linux/04f5866e41fb70690e28397487d8bd8eea7d712a,CVE-2019-11599,https://github.com/torvalds/linux/commit/04f5866e41fb70690e28397487d8bd8eea7d712a,2019-04-29T18:29Z
CWE-362,"CWE-362 static int userfaultfd_register ( struct userfaultfd_ctx * ctx , unsigned long arg ) { struct mm_struct * mm = ctx -> mm ; struct vm_area_struct * vma , * prev , * cur ; int ret ; struct uffdio_register uffdio_register ; struct uffdio_register __user * user_uffdio_register ; unsigned long vm_flags , new_flags ; bool found ; bool basic_ioctls ; unsigned long start , end , vma_end ; user_uffdio_register = ( struct uffdio_register __user * ) arg ; ret = - EFAULT ; if ( copy_from_user ( & uffdio_register , user_uffdio_register , sizeof ( uffdio_register ) - sizeof ( __u64 ) ) ) goto out ; ret = - EINVAL ; if ( ! uffdio_register . mode ) goto out ; if ( uffdio_register . mode & ~ ( UFFDIO_REGISTER_MODE_MISSING | UFFDIO_REGISTER_MODE_WP ) ) goto out ; vm_flags = 0 ; if ( uffdio_register . mode & UFFDIO_REGISTER_MODE_MISSING ) vm_flags |= VM_UFFD_MISSING ; if ( uffdio_register . mode & UFFDIO_REGISTER_MODE_WP ) { vm_flags |= VM_UFFD_WP ; ret = - EINVAL ; goto out ; } ret = validate_range ( mm , uffdio_register . range . start , uffdio_register . range . len ) ; if ( ret ) goto out ; start = uffdio_register . range . start ; end = start + uffdio_register . range . len ; ret = - ENOMEM ; if ( ! mmget_not_zero ( mm ) ) goto out ; <S2SV_StartBug> down_write ( & mm -> mmap_sem ) ; <S2SV_EndBug> vma = find_vma_prev ( mm , start , & prev ) ; if ( ! vma ) goto out_unlock ; ret = - EINVAL ; if ( vma -> vm_start >= end ) goto out_unlock ; if ( is_vm_hugetlb_page ( vma ) ) { unsigned long vma_hpagesize = vma_kernel_pagesize ( vma ) ; if ( start & ( vma_hpagesize - 1 ) ) goto out_unlock ; } found = false ; basic_ioctls = false ; for ( cur = vma ; cur && cur -> vm_start < end ; cur = cur -> vm_next ) { cond_resched ( ) ; BUG_ON ( ! ! cur -> vm_userfaultfd_ctx . ctx ^ ! ! ( cur -> vm_flags & ( VM_UFFD_MISSING | VM_UFFD_WP ) ) ) ; ret = - EINVAL ; if ( ! vma_can_userfault ( cur ) ) goto out_unlock ; ret = - EPERM ; if ( unlikely ( ! ( cur -> vm_flags & VM_MAYWRITE ) ) ) goto out_unlock ; if ( is_vm_hugetlb_page ( cur ) && end <= cur -> vm_end && end > cur -> vm_start ) { unsigned long vma_hpagesize = vma_kernel_pagesize ( cur ) ; ret = - EINVAL ; if ( end & ( vma_hpagesize - 1 ) ) goto out_unlock ; } ret = - EBUSY ; if ( cur -> vm_userfaultfd_ctx . ctx && cur -> vm_userfaultfd_ctx . ctx != ctx ) goto out_unlock ; if ( is_vm_hugetlb_page ( cur ) ) basic_ioctls = true ; found = true ; } BUG_ON ( ! found ) ; if ( vma -> vm_start < start ) prev = vma ; ret = 0 ; do { cond_resched ( ) ; BUG_ON ( ! vma_can_userfault ( vma ) ) ; BUG_ON ( vma -> vm_userfaultfd_ctx . ctx && vma -> vm_userfaultfd_ctx . ctx != ctx ) ; WARN_ON ( ! ( vma -> vm_flags & VM_MAYWRITE ) ) ; if ( vma -> vm_userfaultfd_ctx . ctx == ctx && ( vma -> vm_flags & vm_flags ) == vm_flags ) goto skip ; if ( vma -> vm_start > start ) start = vma -> vm_start ; vma_end = min ( end , vma -> vm_end ) ; new_flags = ( vma -> vm_flags & ~ vm_flags ) | vm_flags ; prev = vma_merge ( mm , prev , start , vma_end , new_flags , vma -> anon_vma , vma -> vm_file , vma -> vm_pgoff , vma_policy ( vma ) , ( ( struct vm_userfaultfd_ctx ) { ctx } ) ) ; if ( prev ) { vma = prev ; goto next ; } if ( vma -> vm_start < start ) { ret = split_vma ( mm , vma , start , 1 ) ; if ( ret ) break ; } if ( vma -> vm_end > end ) { ret = split_vma ( mm , vma , end , 0 ) ; if ( ret ) break ; } next : vma -> vm_flags = new_flags ; vma -> vm_userfaultfd_ctx . ctx = ctx ; skip : prev = vma ; start = vma -> vm_end ; vma = vma -> vm_next ; } while ( vma && vma -> vm_start < end ) ; out_unlock : up_write ( & mm -> mmap_sem ) ; mmput ( mm ) ; if ( ! ret ) { if ( put_user ( basic_ioctls ? UFFD_API_RANGE_IOCTLS_BASIC : UFFD_API_RANGE_IOCTLS , & user_uffdio_register -> ioctls ) ) ret = - EFAULT ; } out : return ret ; }
","<S2SV_ModStart> -> mmap_sem ) ; if ( ! mmget_still_valid ( mm ) ) goto out_unlock
",torvalds@linux/04f5866e41fb70690e28397487d8bd8eea7d712a,CVE-2019-11599,https://github.com/torvalds/linux/commit/04f5866e41fb70690e28397487d8bd8eea7d712a,2019-04-29T18:29Z
