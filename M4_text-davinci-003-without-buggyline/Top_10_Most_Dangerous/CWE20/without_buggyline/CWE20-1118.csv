Original code,Plausible Program,Total Tokens,Sum Entropy,Mean Entropy
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; int bytes_written = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; 

if ( bytes <= 0 ) {
    return -EINVAL;
}

again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } 

if ( copied > 0 ) {
   bytes_written += copied;
   iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; 
}
} while ( iov_iter_count ( i ) ) ;

if ( bytes_written > 0 ) {
   return written ? written : status ; 
} else {
   return -EINVAL;
}
}",567,-49.815658210193064,-0.0878583037216809
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } if (unlikely(!is_input_validated(i))) { status = -EINVAL; break; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }

static int is_input_validated(struct iov_iter *i) {
    // Validate input here
    // Return 1 if validated, 0 otherwise
}",550,-34.40825187871029,-0.06256045796129144
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; 

if(iov_iter_count(i) <= 0) {
    return -EINVAL;
}

do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",514,-12.157799575134929,-0.02365330656641037
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( !iov_iter_is_valid_input(i) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }

The vulnerability has been fixed by adding an additional check to make sure that the input is valid. The original code only checked if the input caused a fault, but it did not check if the input was valid. The fixed code adds a check to make sure the input is valid by using the iov_iter_is_valid_input() function.",555,-40.51312271041358,-0.07299661749624069
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write (struct file *file, struct iov_iter *i, loff_t pos) {
    struct address_space *mapping = file->f_mapping;
    const struct address_space_operations *a_ops = mapping->a_ops;
    long status = 0;
    ssize_t written = 0;
    unsigned int flags = 0;

    if (segment_eq(get_fs(), KERNEL_DS))
        flags |= AOP_FLAG_UNINTERRUPTIBLE;
    
    do {
        struct page *page;
        pgoff_t index;
        unsigned long offset;
        unsigned long bytes;
        size_t copied;
        void *fsdata;
        offset = (pos & (PAGE_CACHE_SIZE - 1));
        index = pos >> PAGE_CACHE_SHIFT;
        bytes = min_t(unsigned long, PAGE_CACHE_SIZE - offset, iov_iter_count(i));
        
        //Added input validation to check for bad user input
        if ((bytes <= 0) || (iov_iter_count(i) < bytes)) {
            status = -EINVAL;
            break;
        }
        
        again:
        if (unlikely(iov_iter_fault_in_readable(i, bytes))) {
            status = -EFAULT;
            break;
        }
        status = a_ops->write_begin(file, mapping, pos, bytes, flags, &page, &fsdata);
        if (unlikely(status))
            break;
        pagefault_disable();
        copied = iov_iter_copy_from_user_atomic(page, i, offset, bytes);
        pagefault_enable();
        flush_dcache_page(page);
        status = a_ops->write_end(file, mapping, pos, bytes, copied, page, fsdata);
        if (unlikely(status < 0))
            break;
        copied = status;
        cond_resched();
        if (unlikely(copied == 0)) {
            bytes = min_t(unsigned long, PAGE_CACHE_SIZE - offset, iov_iter_single_seg_count(i));
            goto again;
        }
        iov_iter_advance(i, copied);
        pos += copied;
        written += copied;
        balance_dirty_pages_ratelimited(mapping);
    } while (iov_iter_count(i));
    return written ? written : status;
}",609,-48.767650886582175,-0.08007824447714643
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } if ( bytes > 0 ) {  // added input validation 
	status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; 
} // added input validation 
} while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",509,-26.708894508819238,-0.052473270154851155
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; if ( iov_iter_count ( i ) <= 0 ) return - EINVAL ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",505,-9.102144182264777,-0.018024047885672825
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; if (!iov_iter_count(i)) { break; } offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",499,-7.3637950453236565,-0.014757104299245805
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; 
if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; 
if (!iov_iter_count(i)) {
    return -EINVAL;
}
 
do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",513,-19.57587402837689,-0.03815959849586138
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } // Validate input here to ensure it is within expected range  if(bytes > 0 && bytes < PAGE_CACHE_SIZE) { status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } else { status = -EINVAL; break; } } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",528,-30.794178510124073,-0.0583223077843259
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : // perform input validation if (bytes > 0) { if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",497,-16.944556226110823,-0.03409367449921695
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; 
if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } else { // Validate that the input is in the proper format/range before writing to the file 
if (!validate_input(i, bytes)) { return -EINVAL; // Return error code for improper input format/range 
} 
} status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",541,-70.9646859842168,-0.1311731718747076
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; if ( iov_iter_count(i) == 0 ) { return 0; } else { do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; if ( !strncmp_s(i, iov_iter_count(i), 0)) { pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
}",532,-37.44182633518506,-0.07037937281049823
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { 
	struct address_space * mapping = file -> f_mapping ;
	const struct address_space_operations * a_ops = mapping -> a_ops ;
	long status = 0 ;
	ssize_t written = 0 ;
	unsigned int flags = 0 ;
	if ( segment_eq ( get_fs ( ) , KERNEL_DS ) )
		flags |= AOP_FLAG_UNINTERRUPTIBLE ;
		
	// Validate input
	if ( !iov_iter_count(i) )
		return 0;
	
	do { 
		struct page * page ;
		pgoff_t index ;
		unsigned long offset ;
		unsigned long bytes ;
		size_t copied ;
		void * fsdata ;
		offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; 
		index = pos >> PAGE_CACHE_SHIFT ; 
		bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; 
		
		again : 
		if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { 
			status = - EFAULT ;
			break ; 
		} 
		status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; 
		if ( unlikely ( status ) ) break ; 
		pagefault_disable ( ) ; 
		copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; 
		pagefault_enable ( ) ; 
		flush_dcache_page ( page ) ; 
		status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; 
		if ( unlikely ( status < 0 ) ) break ; 
		copied = status ; 
		cond_resched ( ) ; 
		if ( unlikely ( copied == 0 ) ) { 
			bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; 
			goto again ; 
		} 
		iov_iter_advance ( i , copied ) ; 
		pos += copied ; 
		written += copied ; 
		balance_dirty_pages_ratelimited ( mapping ) ; 
	} while ( iov_iter_count ( i ) ) ; 
	return written ? written : status ; 
}",672,-43.05095907054837,-0.06406392718831604
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; if (!iov_iter_count(i)) { return -EINVAL; } do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",503,-6.626198592275181,-0.013173357042296583
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write(struct file *file, struct iov_iter *i, loff_t pos) {
    struct address_space *mapping = file->f_mapping;
    const struct address_space_operations *a_ops = mapping->a_ops;
    long status = 0;
    ssize_t written = 0;
    unsigned int flags = 0;

    if (segment_eq(get_fs(), KERNEL_DS))
        flags |= AOP_FLAG_UNINTERRUPTIBLE;

    do {
        struct page *page;
        pgoff_t index;
        unsigned long offset;
        unsigned long bytes;
        size_t copied;
        void *fsdata;

        offset = (pos & (PAGE_CACHE_SIZE - 1));
        index = pos >> PAGE_CACHE_SHIFT;

        // Validate input before using it
        if (iov_iter_count(i) == 0) {
            status = -EINVAL;
            break;
        }
        bytes = min_t(unsigned long, PAGE_CACHE_SIZE - offset, iov_iter_count(i));

    again:
        if (unlikely(iov_iter_fault_in_readable(i, bytes))) {
            status = -EFAULT;
            break;
        }
        status = a_ops->write_begin(file, mapping, pos, bytes, flags, &page, &fsdata);
        if (unlikely(status))
            break;
        pagefault_disable();
        copied = iov_iter_copy_from_user_atomic(page, i, offset, bytes);
        pagefault_enable();
        flush_dcache_page(page);
        status = a_ops->write_end(file, mapping, pos, bytes, copied, page, fsdata);
        if (unlikely(status < 0))
            break;
        copied = status;
        cond_resched();
        if (unlikely(copied == 0)) {
            bytes = min_t(unsigned long, PAGE_CACHE_SIZE - offset, iov_iter_single_seg_count(i));
            goto again;
        }
        iov_iter_advance(i, copied);
        pos += copied;
        written += copied;
        balance_dirty_pages_ratelimited(mapping);
    } while (iov_iter_count(i));

    return written ? written : status;
}",594,-24.905802187486202,-0.041928959911592935
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write(struct file *file, struct iov_iter *i, loff_t pos) {
    struct address_space *mapping = file->f_mapping;
    const struct address_space_operations *a_ops = mapping->a_ops;
    long status = 0;
    ssize_t written = 0;
    unsigned int flags = 0;
    if (segment_eq(get_fs(), KERNEL_DS))
        flags |= AOP_FLAG_UNINTERRUPTIBLE;
    do {
        struct page *page;
        pgoff_t index;
        unsigned long offset;
        unsigned long bytes;
        size_t copied;
        void *fsdata;
        
        offset = (pos & (PAGE_CACHE_SIZE - 1));
        index = pos >> PAGE_CACHE_SHIFT;
        bytes = min_t(unsigned long, PAGE_CACHE_SIZE - offset, iov_iter_count(i));
        
    again:
        if (unlikely(!iov_iter_is_valid(i, bytes))) {
            status = -EINVAL;
            break;
        }
        if (unlikely(iov_iter_fault_in_readable(i, bytes))) {
            status = -EFAULT;
            break;
        }
        status = a_ops->write_begin(file, mapping, pos, bytes, flags, &page, &fsdata);
        if (unlikely(status))
            break;
        pagefault_disable();
        copied = iov_iter_copy_from_user_atomic(page, i, offset, bytes);
        pagefault_enable();
        flush_dcache_page(page);
        status = a_ops->write_end(file, mapping, pos, bytes, copied, page, fsdata);
        if (unlikely(status < 0))
            break;
        copied = status;
        cond_resched();
        if (unlikely(copied == 0)) {
            bytes = min_t(unsigned long, PAGE_CACHE_SIZE - offset, iov_iter_single_seg_count(i));
            goto again;
        }
        iov_iter_advance(i, copied);
        pos += copied;
        written += copied;
        balance_dirty_pages_ratelimited(mapping);
    } while (iov_iter_count(i));
    return written ? written : status;
}",594,-22.72212894037058,-0.0382527423238562
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; 
again : 
if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } 

//Added input validation check
if(bytes > PAGE_CACHE_SIZE || bytes == 0) {
    status = -EINVAL;
    break;
}

status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",532,-26.948846298424932,-0.05065572612485889
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; 

//Validate input
if (pos < 0 || !file || !i || !mapping) 
    return -1;

do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",518,-25.994108486097453,-0.05018167661408775
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; int sz = iov_iter_count(i);  if (sz < 0 || sz > INT_MAX) return -EINVAL; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , sz ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; sz -= copied; } while ( sz > 0 ) ; return written ? written : status ; }",512,-27.75581758458488,-0.05421058121989234
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( !iov_iter_is_valid_readable(i, bytes) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",484,-10.012429244103375,-0.02068683728120532
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; 

//additional code to validate user input 
if ( ! iov_iter_count ( i ) ) {
  return -EINVAL;
}

again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",524,-30.789660157758263,-0.05875889343083638
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:"," 

static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; if (!iov_iter_count(i)){
	return written;
}
	
 offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",508,-26.671848509255486,-0.05250363879774702
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } if (!iov_iter_alignment_ok(i, bytes)) { status = -EINVAL; break; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",511,-12.719115268153057,-0.024890636532589154
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; if (iov_iter_count(i) == 0) return 0; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } if (iov_iter_count(i) > 0 && bytes > 0) { status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",520,-18.36603371003783,-0.035319295596226596
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; 
again : 
if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; }

if ( bytes < 1 ) { status = -EINVAL; break; }

status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",510,-22.633487475187156,-0.04437938720624932
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; 

//added input validation check
if (bytes == 0 || iov_iter_count(i) == 0){
    break;
}

again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",520,-22.08827649880985,-0.04247745480540356
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( !iov_iter_is_valid ( i , bytes ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",479,-9.938044342075871,-0.020747482968843156
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( ! iov_iter_is_valid ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",483,-7.525710495772282,-0.01558118115066725
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write(struct file *file, struct iov_iter *i, loff_t pos) {
    struct address_space *mapping = file->f_mapping;
    const struct address_space_operations *a_ops = mapping->a_ops;
    long status = 0;
    ssize_t written = 0;
    unsigned int flags = 0;
    void *fsdata;

    if (segment_eq(get_fs(), KERNEL_DS))
        flags |= AOP_FLAG_UNINTERRUPTIBLE;

    // Validate the input
    if (iov_iter_count(i) > 0) {
        do {
            struct page *page;
            pgoff_t index;
            unsigned long offset;
            unsigned long bytes;
            size_t copied;

            offset = (pos & (PAGE_CACHE_SIZE - 1));
            index = pos >> PAGE_CACHE_SHIFT;
            bytes = min_t(unsigned long, PAGE_CACHE_SIZE - offset, iov_iter_count(i));

        again:
            if (unlikely(iov_iter_fault_in_readable(i, bytes))) {
                status = -EFAULT;
                break;
            }
            status = a_ops->write_begin(file, mapping, pos, bytes, flags, &page, &fsdata);
            if (unlikely(status))
                break;
            pagefault_disable();
            copied = iov_iter_copy_from_user_atomic(page, i, offset, bytes);
            pagefault_enable();
            flush_dcache_page(page);
            status = a_ops->write_end(file, mapping, pos, bytes, copied, page, fsdata);
            if (unlikely(status < 0))
                break;
            copied = status;
            cond_resched();
            if (unlikely(copied == 0)) {
                bytes = min_t(unsigned long, PAGE_CACHE_SIZE - offset, iov_iter_single_seg_count(i));
                goto again;
            }
            iov_iter_advance(i, copied);
            pos += copied;
            written += copied;
            balance_dirty_pages_ratelimited(mapping);
        } while (iov_iter_count(i));
    } else {
        status = -EINVAL;
    }

    return written ? written : status;
}",593,-29.60002541222884,-0.0499157258216338
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } if(bytes > BUFSIZ) { status = -EINVAL; break; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",504,-17.778704234219603,-0.03527520681392778
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again: if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } if (bytes > mapping->max_write_size) { status = -EINVAL; break; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }

The vulnerability has been fixed by adding an additional condition to the code:

if (bytes > mapping->max_write_size) { status = -EINVAL; break; }

This condition ensures that the bytes written to the file are within the maximum write size for the mapping in order to prevent malicious users from writing to the file beyond its defined size.",586,-70.9853960364449,-0.12113548811680017
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; //Added input validation code here if( bytes > PAGE_CACHE_SIZE || bytes < 0 ){ return 0; } again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",512,-28.801876209521037,-0.056253664471720775
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : //Validate the input if ( bytes <= 0 || bytes > PAGE_CACHE_SIZE || iov_iter_count(i) < 0 ) { status = - EINVAL ; break ; } if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",529,-22.19566215391866,-0.04195777344786136
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } if ( bytes > PAGE_CACHE_SIZE ) { status = -EINVAL; break; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
The fixed code adds a check for the bytes variable with an if-statement to ensure that it does not exceed the maximum allowed size of PAGE_CACHE_SIZE. This will prevent any malicious input from entering the system and causing potential security issues.",560,-54.86085958036161,-0.09796582067921716
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } // Ensure that the given data is valid before performing the write if (!validate_input(i, bytes)) { status = -EINVAL; break; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }

//Added code to validate the given input
bool validate_input(struct iov_iter *i, unsigned long bytes)  { 
    // Check for valid bounds 
    if (bytes < 0 || bytes > iov_iter_count(i)) {
        return false; 
    } 
    return true; 
}",596,-69.92309970319671,-0.11732063708590053
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; //Validate the input before passing it to the do loop if (!iov_iter_count (i) || (iov_iter_count (i) > SSIZE_MAX)) return -EINVAL; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",529,-36.00681303353492,-0.06806580913711704
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } 
if (bytes > 0 && bytes < INT_MAX) {
	status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; 
	if ( unlikely ( status ) ) break ; 
	pagefault_disable ( ) ; 
	copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; 
	pagefault_enable ( ) ; 
	flush_dcache_page ( page ) ; 
	status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; 
	if ( unlikely ( status < 0 ) ) break ; 
	copied = status ; 
	cond_resched ( ) ; 
	if ( unlikely ( copied == 0 ) ) { 
		bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; 
		goto again ; 
	} 
	iov_iter_advance ( i , copied ) ; 
	pos += copied ; 
	written += copied ; 
	balance_dirty_pages_ratelimited ( mapping ) ; 
}
} while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",561,-21.10879979077167,-0.03762709410119727
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( ! is_valid_input(bytes) ) { status = - EINVAL ; break ; } if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }

// Added function to verify input
bool is_valid_input(unsigned long bytes) {
  // Check to make sure input is within expected range
  if (bytes <= 0) {
    return false;
  }

  return true;
}",565,-46.70335347094691,-0.08266080260344585
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; // Validate input if (iov_iter_count(i) > bytes) { status = -EINVAL; break; } again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",513,-15.176192885120235,-0.02958322199828506
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; if ( ! iov_iter_count ( i ) ) { return 0 ; } do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } if ( ! is_user_rw_address ( i -> iov_base , bytes ) ) { break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",528,-23.90898264744437,-0.04528216410500827
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } if(bytes > 0 && bytes < PAGE_CACHE_SIZE) { status = -EINVAL; break; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }

The vulnerability has been fixed by adding a check for the validity of the input. A check is added to ensure that the value of 'bytes' is greater than 0 and less than PAGE_CACHE_SIZE before calling the a_ops write_begin function. If the check fails, the code exits with an error status.",581,-51.51719641746632,-0.08866987335192138
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; if ( iov_iter_count ( i ) > PAGE_CACHE_SIZE ) { status = -EINVAL; break; } offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",516,-9.59705484696051,-0.018598943501861455
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } if (bytes > 0 && bytes < PAGE_CACHE_SIZE) { //Added input validation if (bytes > iov_iter_count(i)) { status = -EINVAL; break; } } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",531,-19.297693729048532,-0.03634217274773735
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) {     
    struct address_space * mapping = file -> f_mapping ; 
    const struct address_space_operations * a_ops = mapping -> a_ops ; 
    long status = 0 ; 
    ssize_t written = 0 ; 
    unsigned int flags = 0 ; 
    if ( segment_eq ( get_fs ( ) , KERNEL_DS ) )
        flags |= AOP_FLAG_UNINTERRUPTIBLE ; 
    do { 
        struct page * page ; 
        pgoff_t index ; 
        unsigned long offset ; 
        unsigned long bytes ; 
        size_t copied ; 
        void * fsdata ; 
        offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; 
        index = pos >> PAGE_CACHE_SHIFT ; 
        bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; 
        again : 
        if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { 
            status = - EFAULT ; 
            break ; 
        } 
        if(strnlen_user(iov_iter_iovec(i).iov_base, bytes) != bytes) {
            status = - EINVAL;
            break;
        }
        status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; 
        if ( unlikely ( status ) ) 
            break ; 
        pagefault_disable ( ) ; 
        copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; 
        pagefault_enable ( ) ; 
        flush_dcache_page ( page ) ; 
        status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; 
        if ( unlikely ( status < 0 ) ) 
            break ; 
        copied = status ; 
        cond_resched ( ) ; 
        if ( unlikely ( copied == 0 ) ) { 
            bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; 
            goto again ; 
        } 
        iov_iter_advance ( i , copied ) ; 
        pos += copied ; 
        written += copied ; 
        balance_dirty_pages_ratelimited ( mapping ) ; 
    } while ( iov_iter_count ( i ) ) ; 
    return written ? written : status ; 
}",664,-38.5675722889373,-0.05808369320623087
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; if ( iov_iter_count ( i ) > 0 ) { do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ||
unlikely ( iov_iter_count ( i ) != bytes ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; } else { return -EINVAL; } }",527,-32.68192550989958,-0.06201503891821552
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:"," 
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( bytes > 0 && unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",490,-11.352957376130375,-0.023169300767613008
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","

static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; if (!iov_iter_count(i) || !iov_iter_is_valid(i)) { status = -EINVAL; break; } again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",519,-11.882290520464332,-0.022894586744632624
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; int max_size = min_t ( unsigned long , PAGE_CACHE_SIZE , iov_iter_single_seg_count ( i ) ) ; do { if ( iov_iter_count ( i ) > max_size ) { return - EINVAL ; } struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { return - EFAULT ; } long status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) { return status ; } pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) { return status ; } copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { return - EIO ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }",509,-34.2772005445082,-0.06734224075541885
"The Original Code is vulnerable to CWE-20: Improper Input Validation. Fix the vulnerability.
Original Code:
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { struct address_space * mapping = file -> f_mapping ; const struct address_space_operations * a_ops = mapping -> a_ops ; long status = 0 ; ssize_t written = 0 ; unsigned int flags = 0 ; if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) flags |= AOP_FLAG_UNINTERRUPTIBLE ; do { struct page * page ; pgoff_t index ; unsigned long offset ; unsigned long bytes ; size_t copied ; void * fsdata ; offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; index = pos >> PAGE_CACHE_SHIFT ; bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; again : if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) { status = - EFAULT ; break ; } status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; if ( unlikely ( status ) ) break ; pagefault_disable ( ) ; copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; pagefault_enable ( ) ; flush_dcache_page ( page ) ; status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; if ( unlikely ( status < 0 ) ) break ; copied = status ; cond_resched ( ) ; if ( unlikely ( copied == 0 ) ) { bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; goto again ; } iov_iter_advance ( i , copied ) ; pos += copied ; written += copied ; balance_dirty_pages_ratelimited ( mapping ) ; } while ( iov_iter_count ( i ) ) ; return written ? written : status ; }
Fixed code:","
static ssize_t generic_perform_write ( struct file * file , struct iov_iter * i , loff_t pos ) { 

struct address_space * mapping = file -> f_mapping ; 
const struct address_space_operations * a_ops = mapping -> a_ops ; 
long status = 0 ; 
ssize_t written = 0 ; 
unsigned int flags = 0 ; 

if ( segment_eq ( get_fs ( ) , KERNEL_DS ) ) {
    flags |= AOP_FLAG_UNINTERRUPTIBLE ; 
}

if(pos < 0) { 
    return -EINVAL; 
}

do { 
    struct page * page ; 
    pgoff_t index ; 
    unsigned long offset ; 
    unsigned long bytes ; 
    size_t copied ; 
    void * fsdata ; 

    offset = ( pos & ( PAGE_CACHE_SIZE - 1 ) ) ; 
    index = pos >> PAGE_CACHE_SHIFT ; 
    bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_count ( i ) ) ; 

again : 
    if ( unlikely ( iov_iter_fault_in_readable ( i , bytes ) ) ) {
        status = - EFAULT ; 
        break ; 
    }
    
    status = a_ops -> write_begin ( file , mapping , pos , bytes , flags , & page , & fsdata ) ; 
    if ( unlikely ( status ) ) { 
        break ; 
    }

    pagefault_disable ( ) ; 
    copied = iov_iter_copy_from_user_atomic ( page , i , offset , bytes ) ; 
    pagefault_enable ( ) ; 
    flush_dcache_page ( page ) ; 
    status = a_ops -> write_end ( file , mapping , pos , bytes , copied , page , fsdata ) ; 
    if ( unlikely ( status < 0 ) ) { 
        break ; 
    }

    copied = status ; 
    cond_resched ( ) ; 
    if ( unlikely ( copied == 0 ) ) { 
        bytes = min_t ( unsigned long , PAGE_CACHE_SIZE - offset , iov_iter_single_seg_count ( i ) ) ; 
        goto again ; 
    }
    
    iov_iter_advance ( i , copied ) ; 
    pos += copied ; 
    written += copied ; 
    balance_dirty_pages_ratelimited ( mapping ) ; 

} while ( iov_iter_count ( i ) ) ; 

return written ? written : status ; 
}",647,-39.01607529782256,-0.060303053010544914
